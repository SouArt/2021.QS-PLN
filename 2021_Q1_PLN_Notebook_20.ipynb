{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-Q1 PLN Notebook 20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2021.QS-PLN/blob/main/2021_Q1_PLN_Notebook_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM0cS2vRmw_C"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2021.Q1]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPuBqCCFCgvR"
      },
      "source": [
        "## **Introdução ao spaCy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMvt1D5QESDK"
      },
      "source": [
        "### **01. Instalação**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGBJTJK-L7uV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "784848ee-15f3-4116-9f2a-a08aebd4dbfa"
      },
      "source": [
        "!pip install spacy --upgrade\n",
        "#!pip install spacy==2.2.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/70/a0b8bd0cb54d8739ba4d6fb3458785c3b9b812b7fbe93b0f10beb1a53ada/spacy-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 288kB/s \n",
            "\u001b[?25hCollecting thinc<8.1.0,>=8.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/08/20e707519bcded1a0caa6fd024b767ac79e4e5d0fb92266bb7dcf735e338/thinc-8.0.2-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 36.3MB/s \n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/53/97dc0197cca9357369b3b71bf300896cf2d3604fa60ffaaf5cbc277de7de/pathy-0.4.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (54.1.2)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Collecting srsly<3.0.0,>=2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/54/76982427ceb495dd19ff982c966708c624b85e03c45bf1912feaf60c7b2d/srsly-2.4.0-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 42.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/65/d5/6c58fc97f3098775e46d8202bf248752e626a8096a0ae9d76aa7c485a09c/spacy_legacy-3.0.1-py2.py3-none-any.whl\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/0a/52ae1c659fc08f13dd7c0ae07b88e4f807ad83fb9954a59b0b0a3d1a8ab6/pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.2)\n",
            "Collecting catalogue<2.1.0,>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/48/5c/493a2f3bb0eac17b1d48129ecfd251f0520b6c89493e9fd0522f534a9e4a/catalogue-2.0.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Collecting smart-open<4.0.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Building wheels for collected packages: smart-open\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=3813cbdd3a7527a963f7bb5563fb31bc0316c752b50bd0b065c50feea668fa1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
            "Successfully built smart-open\n",
            "Installing collected packages: pydantic, catalogue, srsly, thinc, typer, smart-open, pathy, spacy-legacy, spacy\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: smart-open 4.2.0\n",
            "    Uninstalling smart-open-4.2.0:\n",
            "      Successfully uninstalled smart-open-4.2.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.1 pathy-0.4.0 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.5 spacy-legacy-3.0.1 srsly-2.4.0 thinc-8.0.2 typer-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PktHT0dXMNIS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f8907edb-7920-4b12-eff0-51ca9cee4125"
      },
      "source": [
        "import spacy\n",
        "spacy.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.0.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXvCmKxLMdoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3407bb-a87e-4e38-951b-2f31f15ad35a"
      },
      "source": [
        "!python -m spacy download pt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-29 18:24:27.107577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'pt' are deprecated. Please use the\n",
            "full pipeline package name 'pt_core_news_sm' instead.\u001b[0m\n",
            "Collecting pt-core-news-sm==3.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.0.0/pt_core_news_sm-3.0.0-py3-none-any.whl (22.1MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from pt-core-news-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (0.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (54.1.2)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.7.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (8.0.2)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.4.1)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (7.1.2)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.0.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ2s3MS6EXBe"
      },
      "source": [
        "### **02. Marcação POS (*Part-Of-Speech*)**\n",
        "\n",
        "- POS (part-of-speech) atribui para as palavras partes da fala, como substantivos, adjetivos, verbos\n",
        "- Importante para a detecção de entidades no texto, pois primeiro é necessário saber o que o texto contém\n",
        "- Lista de tokens: https://spacy.io/api/annotation#pos-tagging\n",
        "- Português: https://www.sketchengine.eu/portuguese-freeling-part-of-speech-tagset/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T8hIclJNV1b"
      },
      "source": [
        "pln = spacy.load('pt_core_news_sm')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pZAEQVPNku8"
      },
      "source": [
        "documento = pln('Estou aprendendo processamento de linguagem natural na UFABC em Santo André')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg7TeXodNz4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc056a4d-f903-49c0-f732-c0a2aae2675d"
      },
      "source": [
        "for token in documento:\n",
        "  print(token.text, token.pos_)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estou AUX\n",
            "aprendendo VERB\n",
            "processamento NOUN\n",
            "de ADP\n",
            "linguagem NOUN\n",
            "natural ADJ\n",
            "na ADP\n",
            "UFABC PROPN\n",
            "em ADP\n",
            "Santo PROPN\n",
            "André PROPN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGd1tq7mLv_M"
      },
      "source": [
        "### **Legenda**\n",
        "\n",
        "- *lemma*: raiz da palavra\n",
        "- *pos*: parte da fala (classe gramatical)\n",
        "- *tag*: informações morfológicas (por exemplo, se o verbo está no passado)\n",
        "- *dep*: dependência sintática\n",
        "- *shape*: formato (maiúsculo, minúsculo, dígitos)\n",
        "- *alpha*: se é alfabético\n",
        "- *stop*: se é uma *stop word*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sIR8by8Osd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cd6b5a-5021-45cb-b60e-b94a11050a5a"
      },
      "source": [
        "for token in documento:\n",
        "  print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, \n",
        "        token.shape_, token.is_alpha, token.is_stop)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estou Estou AUX AUX aux Xxxxx True True\n",
            "aprendendo aprender VERB VERB ROOT xxxx True False\n",
            "processamento processamento NOUN NOUN obj xxxx True False\n",
            "de de ADP ADP case xx True True\n",
            "linguagem linguagem NOUN NOUN nmod xxxx True False\n",
            "natural natural ADJ ADJ amod xxxx True False\n",
            "na o ADP ADP case xx True True\n",
            "UFABC UFABC PROPN PROPN obl XXXX True False\n",
            "em em ADP ADP case xx True True\n",
            "Santo Santo PROPN PROPN obl Xxxxx True False\n",
            "André André PROPN PROPN flat:name Xxxxx True False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHNRWL_KPabJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3223ce1f-73e5-4100-b78a-285f7a8e629d"
      },
      "source": [
        "for token in documento:\n",
        "  if token.pos_ == 'PROPN':\n",
        "    print(token.text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UFABC\n",
            "Santo\n",
            "André\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DctwAtI_NLym"
      },
      "source": [
        "### **03. Lematização e Stemização**\n",
        "\n",
        "- **Lematização**: \"Lema\" de uma palavra de acordo com seu significado no dicionário - palavra base (análise vocabular e morfológica)\n",
        "- **Stemização**: Extrair o radical (stem) das palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVZ0_xLUQGjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605d85b6-55cf-40e9-beba-722816d46747"
      },
      "source": [
        "for token in documento:\n",
        "  print(token.text, token.lemma_)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estou Estou\n",
            "aprendendo aprender\n",
            "processamento processamento\n",
            "de de\n",
            "linguagem linguagem\n",
            "natural natural\n",
            "na o\n",
            "UFABC UFABC\n",
            "em em\n",
            "Santo Santo\n",
            "André André\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16bshyFfQSF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db25cc63-96ff-4ea7-d09d-599c3984798f"
      },
      "source": [
        "doc = pln('encontrei encontraram encontrarão encontrariam cursando curso cursei')\n",
        "[token.lemma_ for token in doc]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['encontrar',\n",
              " 'encontrar',\n",
              " 'encontrar',\n",
              " 'encontrar',\n",
              " 'cursar',\n",
              " 'cursar',\n",
              " 'cursar']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVz8tGTiZN6C"
      },
      "source": [
        "### **Comparação stemização (NLTK) x lematização (spaCy)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww8qgIxXQt7c"
      },
      "source": [
        "#!pip install nltk --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8G04U93QpbA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "becd98e3-9ce8-4621-b882-18699c89586e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('rslp')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Levz2Ci8Q5hm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "53719c9e-986c-4327-b3fa-0e6209ea2790"
      },
      "source": [
        "stemmer = nltk.stem.RSLPStemmer()\n",
        "stemmer.stem('aprender')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'aprend'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWeL9UDURmEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91150c5-b290-4892-8ab4-4b2aa22abf14"
      },
      "source": [
        "for token in documento:\n",
        "  print(token.text, token.lemma_, stemmer.stem(token.text))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estou Estou est\n",
            "aprendendo aprender aprend\n",
            "processamento processamento process\n",
            "de de de\n",
            "linguagem linguagem lingu\n",
            "natural natural natur\n",
            "na o na\n",
            "UFABC UFABC ufabc\n",
            "em em em\n",
            "Santo Santo sant\n",
            "André André andré\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtacHcwVZ4PH"
      },
      "source": [
        "### **04. Reconhecimento de Entidades Nomeadas**\n",
        "\n",
        "- NER (*Named Entity Recognition*)\n",
        "- Encontrar e classificar entidades no texto, dependendo da base de dados que foi usada para o treinamento (pessoa, localização, empresa, numéricos)\n",
        "- Usado em chatbots para saber o assunto falado\n",
        "- Siglas: https://spacy.io/api/annotation#named-entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA_awKp-aq9j"
      },
      "source": [
        "texto = 'A IBM é uma empresa dos Estados Unidos voltada para a área de informática. Sua sede no Brasil fica em São Paulo e a receita em 2018 foi de aproximadamente 320 bilhões de reais'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldfPLqpVTlbq"
      },
      "source": [
        "documento = pln(texto)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ir1stmgTsbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640cd1d3-98bf-4296-a697-b496e90387cc"
      },
      "source": [
        "for entidade in documento.ents:\n",
        "  print(entidade.text, entidade.label_)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IBM ORG\n",
            "Estados Unidos LOC\n",
            "Brasil LOC\n",
            "São Paulo LOC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfXi2DsYUIU0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "09b9b4e2-c54f-4df3-f10f-4dd1b1ca5d5c"
      },
      "source": [
        "from spacy import displacy\n",
        "displacy.render(documento, style = 'ent', jupyter = True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    IBM\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " é uma empresa dos \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Estados Unidos\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " voltada para a área de informática. Sua sede no \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brasil\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " fica em \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    São Paulo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " e a receita em 2018 foi de aproximadamente 320 bilhões de reais</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDPlvRF2cF7Q"
      },
      "source": [
        "texto = 'Bill Gates nasceu em Seattle em 28/10/1955 e foi o criador da Microsoft'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W00f6-70UYkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f3b816-b4a9-4983-e4e6-4847a4e16bc4"
      },
      "source": [
        "documento = pln(texto)\n",
        "for entidade in documento.ents:\n",
        "  print(entidade.text, entidade.label_)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bill Gates PER\n",
            "Seattle LOC\n",
            "Microsoft ORG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQOX_rbNUlCh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "45a4d77a-5327-47a3-9c19-57f4715dcf5f"
      },
      "source": [
        "displacy.render(documento, style = 'ent', jupyter = True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bill Gates\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " nasceu em \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Seattle\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " em 28/10/1955 e foi o criador da \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86ecZ6oDUsQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068e085c-5547-4bff-d8f9-c94ec8ccdf95"
      },
      "source": [
        "for entidade in documento.ents:\n",
        "  if entidade.label_ == 'PER':\n",
        "    print(entidade.text)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bill Gates\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt4Rg6ekdsmF"
      },
      "source": [
        "### **05. *Stop words***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stg3FUaoeW4I"
      },
      "source": [
        "Palavras que aparecem com muita frequência e que não apresentam muito significado (e, a, de, da etc.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ2Mxo4vVZ-w"
      },
      "source": [
        "from spacy.lang.pt.stop_words import STOP_WORDS"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FZdoyg2VgdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "855278f4-a300-46f9-9cc2-c452750b0ee0"
      },
      "source": [
        "print(STOP_WORDS)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'coisa', 'iniciar', 'todos', 'pode', 'estiveste', 'usar', 'dezassete', 'devem', 'quinto', 'mas', 'vossas', 'pelas', 'mil', 'contra', 'se', 'elas', 'à', 'ela', 'nível', 'quieto', 'meus', 'conhecido', 'fez', 'após', 'aqui', 'aqueles', 'vindo', 'obrigado', 'poderá', 'ademais', 'momento', 'eventual', 'estou', 'sim', 'certamente', 'adeus', 'contudo', 'parte', 'conselho', 'dão', 'aquele', 'menos', 'em', 'os', 'tais', 'zero', 'seis', 'corrente', 'cá', 'ambos', 'nada', 'apoia', 'tiveste', 'depois', 'você', 'um', 'sabe', 'nove', 'menor', 'quando', 'vários', 'aí', 'dezoito', 'grandes', 'tivestes', 'lá', 'muito', 'direita', 'ou', 'como', 'antes', 'geral', 'sempre', 'tendes', 'diz', 'faço', 'ser', 'embora', 'estará', 'fui', 'novo', 'tempo', 'meio', 'te', 'deverá', 'tanta', 'fazer', 'vens', 'vossa', 'povo', 'desta', 'desde', 'favor', 'daquela', 'comprida', 'enquanto', 'através', 'segundo', 'também', 'vós', 'meu', 'forma', 'possivelmente', 'grande', 'podem', 'todo', 'de', 'debaixo', 'estado', 'mais', 'oitavo', 'breve', 'seu', 'obrigada', 'bom', 'doze', 'estava', 'nós', 'maior', 'vão', 'próprio', 'vinte', 'és', 'porque', 'ligado', 'máximo', 'tem', 'número', 'bastante', 'novas', 'pouca', 'inclusive', 'está', 'fazem', 'parece', 'baixo', 'lado', 'lhe', 'me', 'dois', 'certeza', 'dar', 'fazes', 'quarto', 'possível', 'primeira', 'segunda', 'treze', 'tiveram', 'sete', 'e', 'o', 'tuas', 'para', 'pela', 'tarde', 'esse', 'minha', 'usa', 'outras', 'seria', 'vez', 'somos', 'este', 'teve', 'dessa', 'todas', 'nas', 'apontar', 'temos', 'uns', 'daquele', 'outros', 'terceiro', 'que', 'esta', 'custa', 'cedo', 'atrás', 'caminho', 'vêm', 'tentei', 'local', 'da', 'qualquer', 'logo', 'só', 'pois', 'relação', 'quero', 'apenas', 'irá', 'fostes', 'isto', 'faz', 'quer', 'estiveram', 'quinze', 'já', 'mesmo', 'três', 'sexta', 'até', 'somente', 'vosso', 'estás', 'vai', 'dizer', 'catorze', 'vezes', 'nessa', 'por', 'vais', 'tal', 'esteve', 'maiorias', 'vos', 'maioria', 'nova', 'estes', 'esses', 'teus', 'cento', 'poder', 'tudo', 'ambas', 'neste', 'ver', 'questão', 'põe', 'ir', 'quais', 'vinda', 'podia', 'sétimo', 'conhecida', 'nenhuma', 'dez', 'seus', 'tua', 'nesta', 'assim', 'outra', 'vem', 'lugar', 'dentro', 'do', 'quanto', 'estivestes', 'cima', 'fazemos', 'ali', 'sua', 'talvez', 'querem', 'estivemos', 'sois', 'fora', 'entre', 'nossos', 'sexto', 'não', 'puderam', 'essas', 'toda', 'vocês', 'primeiro', 'novos', 'sétima', 'umas', 'num', 'próxima', 'põem', 'com', 'quinta', 'ter', 'a', 'pegar', 'acerca', 'das', 'na', 'números', 'nossa', 'fomos', 'ponto', 'sob', 'mal', 'pontos', 'aos', 'têm', 'são', 'aquilo', 'no', 'pelos', 'sei', 'dezasseis', 'tão', 'tentaram', 'grupo', 'nem', 'foi', 'algo', 'perto', 'naquele', 'foste', 'meses', 'numa', 'ontem', 'foram', 'diante', 'oitava', 'apoio', 'desse', 'ora', 'uma', 'pelo', 'posso', 'ainda', 'minhas', 'dizem', 'for', 'longe', 'sobre', 'cinco', 'área', 'fazeis', 'onde', 'porquanto', 'porquê', 'bem', 'tentar', 'alguns', 'aquela', 'valor', 'suas', 'des', 'portanto', 'tivemos', 'quatro', 'nossas', 'veja', 'era', 'às', 'tanto', 'agora', 'disso', 'ao', 'boa', 'próximo', 'qual', 'as', 'quê', 'cuja', 'além', 'sou', 'dos', 'comprido', 'aquelas', 'nosso', 'onze', 'inicio', 'isso', 'quieta', 'algumas', 'terceira', 'estive', 'fará', 'tipo', 'deste', 'dá', 'nuns', 'tente', 'nos', 'fim', 'eles', 'final', 'pôde', 'então', 'falta', 'naquela', 'sistema', 'pouco', 'muitos', 'duas', 'fazia', 'nesse', 'demais', 'tu', 'estas', 'essa', 'exemplo', 'último', 'teu', 'vossos', 'estar', 'deve', 'saber', 'eu', 'cada', 'dezanove', 'oito', 'quem', 'tive', 'tenho', 'é', 'cujo', 'sem', 'porém', 'tens', 'nunca', 'quarta', 'posição', 'mês', 'partir', 'ele', 'estão'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebS0ad1CVpD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc02af7a-229d-43f4-d47a-1069e208752a"
      },
      "source": [
        "len(STOP_WORDS)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k3mNHEBVtWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e8b0d6-9332-4824-8c5e-3cb402207131"
      },
      "source": [
        "pln.vocab['ir'].is_stop"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQmM-k23V1Mk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd7883e-0365-41be-b977-a13ce6996021"
      },
      "source": [
        "pln.vocab['caminhar'].is_stop"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4eI813V8h7"
      },
      "source": [
        "documento = pln('Estou aprendendo processamento de linguagem natural na UFABC em Santo André')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVtMxX__WE9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "551aae6e-3921-4a48-c5cf-be85698c7894"
      },
      "source": [
        "for token in documento:\n",
        "  if not pln.vocab[token.text].is_stop:\n",
        "    print(token.text)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aprendendo\n",
            "processamento\n",
            "linguagem\n",
            "natural\n",
            "UFABC\n",
            "Santo\n",
            "André\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcgAkuB346vV"
      },
      "source": [
        "### **06. Tokenização**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZuGK8j_n8WB"
      },
      "source": [
        "documento = pln('Estou aprendendo processamento de linguagem natural na UFABC em Santo André')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtr3c4WEoA0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34fd4176-9318-4dec-ad82-6ae805b32a80"
      },
      "source": [
        "for token in documento:\n",
        "  print(token)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estou\n",
            "aprendendo\n",
            "processamento\n",
            "de\n",
            "linguagem\n",
            "natural\n",
            "na\n",
            "UFABC\n",
            "em\n",
            "Santo\n",
            "André\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0D5zthsoJi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3708805a-282f-43d0-efba-3f4a86827a24"
      },
      "source": [
        "documento1 = 'Estou aprendendo processamento de linguagem natural na UFABC em Santo André'\n",
        "documento1.split(' ')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Estou',\n",
              " 'aprendendo',\n",
              " 'processamento',\n",
              " 'de',\n",
              " 'linguagem',\n",
              " 'natural',\n",
              " 'na',\n",
              " 'UFABC',\n",
              " 'em',\n",
              " 'Santo',\n",
              " 'André']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQDkY5HOwube"
      },
      "source": [
        "**Referência**:\n",
        "\n",
        "Notebook disponibilizado no Curso de [Processamento de Linguagem Natural com spaCy e Python](https://iaexpert.academy/courses/processamento-linguagem-natural-spacy-python/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXZVr2yPNz9F"
      },
      "source": [
        "**Mais informações** em [*Natural Language Processing With spaCy in Python*](https://realpython.com/natural-language-processing-spacy-python/)."
      ]
    }
  ]
}
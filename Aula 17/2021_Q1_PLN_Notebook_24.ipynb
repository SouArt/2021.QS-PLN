{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-Q1 PLN Notebook 24.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqNd8l+GdPBz35X0lp7L7T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2021.QS-PLN/blob/main/2021_Q1_PLN_Notebook_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOjipVo3RSqP"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2020.QS]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENTfe60CRXjm"
      },
      "source": [
        "### **Modelagem de Tópicos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bHg3XhEReoI"
      },
      "source": [
        "doc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\n",
        "doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
        "doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
        "doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
        "doc_e = \"Health professionals say that brocolli is good for your health.\"\n",
        "\n",
        "# compile sample documents into a list\n",
        "doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FX-9zgERmPe"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgPx_RZZRrnW"
      },
      "source": [
        "raw = doc_a.lower()\n",
        "tokens = tokenizer.tokenize(raw)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JXtGz5vRyNg",
        "outputId": "8c2d32bb-b9fc-4c22-953d-1c22a3ff12a6"
      },
      "source": [
        "print(tokens)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['brocolli', 'is', 'good', 'to', 'eat', 'my', 'brother', 'likes', 'to', 'eat', 'good', 'brocolli', 'but', 'not', 'my', 'mother']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHuYodRFSKt8",
        "outputId": "2829d2c2-8146-49ee-be35-1460d090f636"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "en_stop = stopwords.words('english')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ghev_j0Sd_B"
      },
      "source": [
        "# remove stop words from tokens\n",
        "stopped_tokens = [i for i in tokens if not i in en_stop]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaC6CR3qSlsO",
        "outputId": "0c8479d4-e978-4e85-ef3d-f1a1f96c4ed9"
      },
      "source": [
        "print(stopped_tokens)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['brocolli', 'good', 'eat', 'brother', 'likes', 'eat', 'good', 'brocolli', 'mother']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aavKdfbSs6x"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# Create p_stemmer of class PorterStemmer\n",
        "p_stemmer = PorterStemmer()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjoA0AjOSz8B"
      },
      "source": [
        "# stem token\n",
        "texts  = [p_stemmer.stem(i) for i in stopped_tokens]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYGlPJ6cS3_g",
        "outputId": "02996f7d-8428-4017-8449-73ba5f3103c0"
      },
      "source": [
        "print(texts)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['brocolli', 'good', 'eat', 'brother', 'like', 'eat', 'good', 'brocolli', 'mother']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUD881ieS-dX"
      },
      "source": [
        "from gensim import corpora, models\n",
        "\n",
        "dictionary = corpora.Dictionary([texts])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0R2GMIYTdnC"
      },
      "source": [
        "corpus = [dictionary.doc2bow(text) for text in [texts]]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E3RUHuHTopH",
        "outputId": "32f214d9-3b62-4331-c900-2b5636c773c1"
      },
      "source": [
        "print(corpus[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 2), (1, 1), (2, 2), (3, 2), (4, 1), (5, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yifCwkL5TqAD"
      },
      "source": [
        "import gensim\n",
        "from gensim import models\n",
        "\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary, passes=20)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM4J00cKUgiY",
        "outputId": "8979ad23-8b72-48ba-e912-17e57b59b689"
      },
      "source": [
        "print(ldamodel.print_topics(num_topics=3, num_words=3))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.167*\"mother\" + 0.167*\"like\" + 0.167*\"brother\"'), (1, '0.212*\"good\" + 0.212*\"brocolli\" + 0.212*\"eat\"'), (2, '0.167*\"brother\" + 0.167*\"mother\" + 0.167*\"like\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiFa-uhcUkqN"
      },
      "source": [
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=2, id2word = dictionary, passes=20)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ3L1GgRUqxL",
        "outputId": "463733a4-59a5-4c43-ac23-0cfdb021ae12"
      },
      "source": [
        "print(ldamodel.print_topics(num_topics=2, num_words=4))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.167*\"brocolli\" + 0.167*\"eat\" + 0.167*\"good\" + 0.167*\"brother\"'), (1, '0.209*\"good\" + 0.209*\"eat\" + 0.209*\"brocolli\" + 0.125*\"mother\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZQl-fCdU5Ly"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim import corpora, models\n",
        "import gensim\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "# create English stop words list\n",
        "en_stop = stopwords.words('english')\n",
        "\n",
        "# Create p_stemmer of class PorterStemmer\n",
        "p_stemmer = PorterStemmer()\n",
        "    \n",
        "# create sample documents\n",
        "doc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\n",
        "doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
        "doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
        "doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
        "doc_e = \"Health professionals say that brocolli is good for your health.\" \n",
        "\n",
        "# compile sample documents into a list\n",
        "doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]\n",
        "\n",
        "# list for tokenized documents in loop\n",
        "texts = []\n",
        "\n",
        "# loop through document list\n",
        "for i in doc_set:\n",
        "    \n",
        "    # clean and tokenize document string\n",
        "    raw = i.lower()\n",
        "    tokens = tokenizer.tokenize(raw)\n",
        "\n",
        "    # remove stop words from tokens\n",
        "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
        "    \n",
        "    # stem tokens\n",
        "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
        "    \n",
        "    # add tokens to list\n",
        "    texts.append(stemmed_tokens)\n",
        "\n",
        "# turn our tokenized documents into a id <-> term dictionary\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "    \n",
        "# convert tokenized documents into a document-term matrix\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# generate LDA model\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=2, id2word = dictionary, passes=20)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWydU2wrVQcG",
        "outputId": "b5cc5301-3b1e-4803-9b3f-7769be08ca15"
      },
      "source": [
        "print(ldamodel.print_topics(num_topics=2, num_words=4))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.072*\"drive\" + 0.043*\"health\" + 0.043*\"pressur\" + 0.043*\"expert\"'), (1, '0.081*\"good\" + 0.081*\"brocolli\" + 0.059*\"brother\" + 0.059*\"mother\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17hOc0VgV4E_"
      },
      "source": [
        "**Mais informações:**\n",
        "\n",
        "> https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html"
      ]
    }
  ]
}
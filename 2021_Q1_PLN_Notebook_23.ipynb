{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-Q1 PLN Notebook 23.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNxtH1DjWkB46rBXgkOJQ6g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2021.QS-PLN/blob/main/2021_Q1_PLN_Notebook_23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk8y4Xyp9eRD"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2020.QS]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q9RGmcs9iAe"
      },
      "source": [
        "### **Modelagem de Tópicos com LDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEN81Am69mp0"
      },
      "source": [
        "Neste exemplo faremos a modelagem de tópicos no texto obtido de artigos da Wikipedia. Para baixar a biblioteca da `Wikipedia`, execute o seguinte comando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIU0fm91XJ6i",
        "outputId": "b22f89d8-8478-440e-f7e2-269f0b8427ac"
      },
      "source": [
        "!pip install wikipedia"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0geNTLJ-HEO"
      },
      "source": [
        "Para visualizar nosso modelo de tópicos, usaremos a biblioteca `pyLDAvis`. Para fazer o download da biblioteca, execute o seguinte comando `pip`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTuYNgZ3XOfQ",
        "outputId": "1e7c676d-f583-47a0-9099-e102d368dec4"
      },
      "source": [
        "!pip install pyLDAvis==2.1.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyLDAvis==2.1.2 in /usr/local/lib/python3.7/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.19.5)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.15)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.4.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (3.6.4)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.1.5)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (2.11.3)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (0.36.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (2.7.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (0.16.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (1.15.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (1.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (20.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (8.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (54.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.7.2->pyLDAvis==2.1.2) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMHkBLFlXVeo",
        "outputId": "b97bb020-c84a-46ad-a72f-88f5fa069e17"
      },
      "source": [
        "# scraping Wikipedia Articles\n",
        "\n",
        "import wikipedia\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "global_warming = wikipedia.page(\"Natural language processing\")\n",
        "artificial_intelligence = wikipedia.page(\"Artificial Intelligence\")\n",
        "mona_lisa = wikipedia.page(\"Mona Lisa\")\n",
        "eiffel_tower = wikipedia.page(\"Eiffel Tower\")\n",
        "\n",
        "corpus = [global_warming.content, artificial_intelligence.content, mona_lisa.content, eiffel_tower.content]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4u-i7QR-qPX"
      },
      "source": [
        "No script acima, primeiro importamos as bibliotecas `wikipedia` e `nltk`. Também baixamos as *stop words* em inglês. \n",
        "\n",
        ">\n",
        "Em seguida, baixamos o artigo da Wikipedia especificando o tópico para o objeto `page` da biblioteca `wikipedia`. O objeto retornado contém informações sobre a página baixada.\n",
        "\n",
        ">\n",
        "Para recuperar o conteúdo da página Web, podemos usar o atributo `content`. O conteúdo de todos os quatro artigos é armazenado na lista denominada `corpus`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VutL6XK9_ju8"
      },
      "source": [
        "**Pré-processamento dos dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87WuHpKU_ncd"
      },
      "source": [
        "Para realizar a modelagem de tópicos via LDA, precisamos de um dicionário de dados e da sacola de palavras (*bag of words*) do corpus. Para isso, precisamos de dados na forma de tokens.\n",
        "\n",
        ">\n",
        "Além disso, precisamos remover pontuações e *stop words* de nosso conjunto de dados. Por uma questão de uniformidade, converteremos todos os tokens para minúsculas e também os lematizaremos. Além disso, removeremos todos os tokens com menos de 5 caracteres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "359RX4uaXynQ"
      },
      "source": [
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "stemmer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(document):\n",
        "        # remove all the special characters\n",
        "        document = re.sub(r'\\W', ' ', str(document))\n",
        "\n",
        "        # remove all single characters\n",
        "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "\n",
        "        # remove single characters from the start\n",
        "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
        "\n",
        "        # substituting multiple spaces with single space\n",
        "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "\n",
        "        # removing prefixed 'b'\n",
        "        document = re.sub(r'^b\\s+', '', document)\n",
        "\n",
        "        # converting to lowercase\n",
        "        document = document.lower()\n",
        "\n",
        "        # lemmatization\n",
        "        tokens = document.split()\n",
        "        tokens = [stemmer.lemmatize(word) for word in tokens]\n",
        "        tokens = [word for word in tokens if word not in en_stop]\n",
        "        tokens = [word for word in tokens if len(word)  > 5]\n",
        "\n",
        "        return tokens"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q0sy0gqYa8y",
        "outputId": "ba0e9e5d-399a-42f2-f8ba-87243a5c614f"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTYjeuKGYSbO"
      },
      "source": [
        "processed_data = [];\n",
        "for doc in corpus:\n",
        "    tokens = preprocess_text(doc)\n",
        "    processed_data.append(tokens)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBG4PAmDA7NB"
      },
      "source": [
        "No trecho de código acima nós iteramos através da lista de `corpus` que contém os quatro artigos da Wikipedia na forma de strings. Em cada iteração, passamos o documento para o método `preprocess_text` que criamos anteriormente. O método retorna tokens para esse documento específico. Os tokens são armazenados na lista `processed_data`.\n",
        "\n",
        ">\n",
        "No final do loop `for`, todos os tokens de todos os quatro artigos serão armazenados na lista `processed_data`. Agora podemos usar essa lista para criar um dicionário e a sacola de palavras correspondente ao corpus. O seguinte *script* faz isso:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP99ajZTYhQn"
      },
      "source": [
        "from gensim import corpora\n",
        "\n",
        "gensim_dictionary = corpora.Dictionary(processed_data)\n",
        "gensim_corpus = [gensim_dictionary.doc2bow(token, allow_update=True) for token in processed_data]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtBrjJqPB9GX"
      },
      "source": [
        "A seguir, salvaremos nosso dicionário, bem como a sacola de palavras do corpus usando `pickle`. Usaremos o dicionário salvo mais tarde para fazer previsões sobre os novos dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g87fTizNYic1"
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(gensim_corpus, open('gensim_corpus_corpus.pkl', 'wb'))\n",
        "gensim_dictionary.save('gensim_dictionary.gensim')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pj2nlTBCZYB"
      },
      "source": [
        "Agora, temos tudo o que é necessário para criar o **modelo LDA** no `Gensim`. Usaremos a classe `LdaModel` do módulo `gensim.models.ldamodel` para criar o modelo LDA. Precisamos passar a sacola de palavras do corpus que criamos anteriormente como o primeiro parâmetro para o construtor `LdaModel`, seguido pelo número de tópicos, o dicionário que criamos anteriormente e o número de passagens (número de iterações para o modelo)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pCEwsaOYmG3"
      },
      "source": [
        "import gensim\n",
        "\n",
        "lda_model = gensim.models.ldamodel.LdaModel(gensim_corpus, num_topics=4, id2word=gensim_dictionary, passes=20)\n",
        "lda_model.save('gensim_model.gensim')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kH2j-XqDlY1"
      },
      "source": [
        "Sim, é assim tão simples. No script acima, criamos o modelo LDA de nosso conjunto de dados e o salvamos.\n",
        "\n",
        ">\n",
        "A seguir, vamos imprimir 10 palavras para cada tópico. Para fazer isso, podemos usar o método `print_topics`. Execute o seguinte *script*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMwTh6ZqYqUV",
        "outputId": "7631322f-971a-4fdb-e2f5-bae79ca3d48a"
      },
      "source": [
        "topics = lda_model.print_topics(num_words=10)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '0.000*\"eiffel\" + 0.000*\"intelligence\" + 0.000*\"second\" + 0.000*\"system\" + 0.000*\"painting\" + 0.000*\"artificial\" + 0.000*\"machine\" + 0.000*\"french\" + 0.000*\"leonardo\" + 0.000*\"learning\"')\n",
            "(1, '0.028*\"eiffel\" + 0.008*\"second\" + 0.007*\"french\" + 0.006*\"structure\" + 0.006*\"exposition\" + 0.005*\"tallest\" + 0.005*\"engineer\" + 0.005*\"design\" + 0.004*\"million\" + 0.004*\"france\"')\n",
            "(2, '0.022*\"painting\" + 0.015*\"language\" + 0.010*\"leonardo\" + 0.008*\"natural\" + 0.006*\"system\" + 0.006*\"machine\" + 0.006*\"louvre\" + 0.005*\"portrait\" + 0.005*\"learning\" + 0.005*\"sentence\"')\n",
            "(3, '0.020*\"intelligence\" + 0.015*\"machine\" + 0.014*\"artificial\" + 0.011*\"system\" + 0.011*\"problem\" + 0.008*\"research\" + 0.008*\"knowledge\" + 0.007*\"approach\" + 0.006*\"learning\" + 0.006*\"computer\"')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7aSkuP6DziY"
      },
      "source": [
        "**IMPORTANTE**: A ordem dos tópicos pode mudar a cada execução do código.\n",
        ">\n",
        "O tópico 3 contém palavras como *language*, *natural*, *system*, *machine* etc. Podemos supor que essas palavras pertencem ao tópico relacionado a PLN.\n",
        "\n",
        "Da mesma forma, o primeiro (0) contém palavras como *intelligence*, *machine*, *research* etc. Podemos supor que essas palavras pertencem ao tópico relacionado à Inteligência Artificial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3491PqsqGKvb"
      },
      "source": [
        "Podemos ver claramente que o modelo LDA identificou com sucesso os quatro tópicos em nosso conjunto de dados.\n",
        "\n",
        ">\n",
        "É importante mencionar aqui que o LDA é um algoritmo de aprendizado não supervisionado e, em problemas do mundo real, você não saberá sobre os tópicos do conjunto de dados de antemão. Você simplesmente receberá um corpus, os tópicos serão criados usando LDA e, em seguida, os nomes dos tópicos dependem de você."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbkZqLLPGWVe"
      },
      "source": [
        "Vamos agora criar 8 tópicos usando nosso conjunto de dados. Iremos imprimir 5 palavras por tópico:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpuE2OUhYuLW",
        "outputId": "b1e78c63-60e5-4b13-f7fa-dd095b4bea0a"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(gensim_corpus, num_topics=8, id2word=gensim_dictionary, passes=15)\n",
        "lda_model.save('gensim_model.gensim')\n",
        "topics = lda_model.print_topics(num_words=5)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '0.000*\"intelligence\" + 0.000*\"artificial\" + 0.000*\"research\" + 0.000*\"machine\" + 0.000*\"problem\"')\n",
            "(1, '0.000*\"language\" + 0.000*\"machine\" + 0.000*\"system\" + 0.000*\"intelligence\" + 0.000*\"natural\"')\n",
            "(2, '0.000*\"intelligence\" + 0.000*\"eiffel\" + 0.000*\"painting\" + 0.000*\"machine\" + 0.000*\"language\"')\n",
            "(3, '0.000*\"painting\" + 0.000*\"machine\" + 0.000*\"system\" + 0.000*\"intelligence\" + 0.000*\"language\"')\n",
            "(4, '0.013*\"intelligence\" + 0.012*\"machine\" + 0.012*\"painting\" + 0.010*\"language\" + 0.010*\"system\"')\n",
            "(5, '0.000*\"painting\" + 0.000*\"leonardo\" + 0.000*\"portrait\" + 0.000*\"language\" + 0.000*\"louvre\"')\n",
            "(6, '0.032*\"eiffel\" + 0.009*\"second\" + 0.008*\"french\" + 0.007*\"structure\" + 0.007*\"exposition\"')\n",
            "(7, '0.000*\"intelligence\" + 0.000*\"system\" + 0.000*\"eiffel\" + 0.000*\"language\" + 0.000*\"machine\"')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhVl-zxdGiE8"
      },
      "source": [
        "Novamente, o número de tópicos que deseja criar depende de você. Continue tentando números diferentes até encontrar tópicos adequados. Para nosso conjunto de dados, o número adequado de tópicos é 4, pois já sabemos que nosso corpus contém palavras de quatro artigos diferentes. Reverta para quatro tópicos executando o seguinte *script*:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnZMap1RGwAV"
      },
      "source": [
        "Desta vez, você verá resultados diferentes, uma vez que os valores iniciais para os parâmetros LDA são escolhidos aleatoriamente. Os resultados desta vez são os seguintes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVqr-iLiY0XF",
        "outputId": "1e7eb723-7608-4b03-be0a-dac997d01c3b"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(gensim_corpus, num_topics=4, id2word=gensim_dictionary, passes=20)\n",
        "lda_model.save('gensim_model.gensim')\n",
        "topics = lda_model.print_topics(num_words=10)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '0.000*\"machine\" + 0.000*\"painting\" + 0.000*\"system\" + 0.000*\"intelligence\" + 0.000*\"language\" + 0.000*\"research\" + 0.000*\"artificial\" + 0.000*\"problem\" + 0.000*\"eiffel\" + 0.000*\"natural\"')\n",
            "(1, '0.020*\"intelligence\" + 0.015*\"machine\" + 0.014*\"artificial\" + 0.011*\"system\" + 0.011*\"problem\" + 0.008*\"research\" + 0.008*\"knowledge\" + 0.007*\"approach\" + 0.006*\"learning\" + 0.006*\"computer\"')\n",
            "(2, '0.028*\"eiffel\" + 0.008*\"second\" + 0.007*\"french\" + 0.006*\"structure\" + 0.006*\"exposition\" + 0.005*\"tallest\" + 0.005*\"engineer\" + 0.005*\"design\" + 0.004*\"million\" + 0.004*\"france\"')\n",
            "(3, '0.022*\"painting\" + 0.015*\"language\" + 0.010*\"leonardo\" + 0.008*\"natural\" + 0.006*\"system\" + 0.006*\"machine\" + 0.006*\"louvre\" + 0.005*\"portrait\" + 0.005*\"learning\" + 0.005*\"sentence\"')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-VkZZJ-G7Nn"
      },
      "source": [
        "**Avaliando o modelo LDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-ObCg3AG97W"
      },
      "source": [
        "Conforme mencionado anteriormente, os modelos de aprendizagem não supervisionados são difíceis de avaliar, uma vez que não existe uma verdade concreta contra a qual possamos testar a saída de nosso modelo.\n",
        "\n",
        ">\n",
        "Suponha que temos um novo documento de texto e queremos encontrar seu tópico usando o modelo LDA que acabamos de criar, podemos fazer isso usando o seguinte *script*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sYxh1avY4Ou",
        "outputId": "e1ce6880-d941-4338-b5e6-bdc75254aac9"
      },
      "source": [
        "test_doc = 'Great structures are build to remember an event happened in the history.'\n",
        "test_doc = preprocess_text(test_doc)\n",
        "bow_test_doc = gensim_dictionary.doc2bow(test_doc)\n",
        "\n",
        "print(lda_model.get_document_topics(bow_test_doc))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.08337962), (1, 0.08514082), (2, 0.7433581), (3, 0.08812153)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwnMao7jHe_2"
      },
      "source": [
        "No *script* acima, criamos uma string, criamos sua representação no dicionário e então convertemos a string no corpus do saco de palavras. A representação do saco de palavras é então passada para o método `get_document_topics`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1RGmeF8H03w"
      },
      "source": [
        "A saída mostra que há 74,1% de chance de que o novo documento pertença ao tópico 3 (consulte as palavras para o tópico 3 na última saída). Da mesma forma, há 8,4% de chance de este documento pertencer ao primeiro tópico (0). Se olharmos para o tópico 3, ele contém palavras relacionadas à Torre Eiffel. Nosso documento de teste também contém palavras relacionadas a estruturas e edifícios. Portanto, foi atribuído o tópico 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaEFKliXIgps"
      },
      "source": [
        "Outra forma de avaliar o modelo LDA é por meio de `Perplexity` (Perplexidade) e `Coherence Score` (Coerência)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPD0j72sIs5V"
      },
      "source": [
        "Como regra geral para um bom modelo de LDA, a pontuação de perplexidade deve ser baixa, enquanto a coerência deve ser alta. A biblioteca Gensim possui uma classe `CoherenceModel` que pode ser usada para encontrar a coerência do modelo LDA. Para perplexidade, o objeto `LdaModel` contém o método `log_perplexity` que pega uma sacola de palavras como parâmetro e retorna a perplexidade correspondente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri16KbcbY_OG",
        "outputId": "dc226e80-f262-4c9c-d81e-1fc4824bce1b"
      },
      "source": [
        "print('\\nPerplexity:', lda_model.log_perplexity(gensim_corpus))\n",
        "\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "coherence_score_lda = CoherenceModel(model=lda_model, texts=processed_data, dictionary=gensim_dictionary, coherence='c_v')\n",
        "coherence_score = coherence_score_lda.get_coherence()\n",
        "\n",
        "print('\\nCoherence Score:', coherence_score)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity: -7.6300186146211155\n",
            "\n",
            "Coherence Score: 0.552999173152782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AShpPJi2JRdE"
      },
      "source": [
        "**Visualizando o modelo LDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqZSVQBxJjSk"
      },
      "source": [
        "Para visualizar nossos dados, podemos usar a biblioteca `pyLDAvis` que baixamos no início."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "Qy8MKyyeZDCz",
        "outputId": "98234940-034c-4e07-f8ee-2b3f1d08a9f1"
      },
      "source": [
        "gensim_dictionary = gensim.corpora.Dictionary.load('gensim_dictionary.gensim')\n",
        "gensim_corpus = pickle.load(open('gensim_corpus_corpus.pkl', 'rb'))\n",
        "lda_model = gensim.models.ldamodel.LdaModel.load('gensim_model.gensim')\n",
        "\n",
        "import pyLDAvis.gensim\n",
        "\n",
        "lda_visualization = pyLDAvis.gensim.prepare(lda_model, gensim_corpus, gensim_dictionary, sort_topics=False)\n",
        "pyLDAvis.display(lda_visualization)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el3341401170526452007689437700\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el3341401170526452007689437700_data = {\"mdsDat\": {\"x\": [0.023961566406540426, -0.12513250306221776, 0.1638964755242755, -0.06272553886859826], \"y\": [0.00903984521111425, 0.09691854816336834, 0.023231433916720334, -0.12918982729120296], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [0.010106659589311943, 42.63102924077476, 20.891794630307295, 36.467069469328635]}, \"tinfo\": {\"Term\": [\"eiffel\", \"painting\", \"intelligence\", \"artificial\", \"leonardo\", \"language\", \"machine\", \"problem\", \"second\", \"portrait\", \"french\", \"intelligent\", \"knowledge\", \"exposition\", \"louvre\", \"researcher\", \"sentence\", \"tallest\", \"structure\", \"approach\", \"speech\", \"engineer\", \"research\", \"parsing\", \"natural\", \"restaurant\", \"design\", \"italian\", \"semantics\", \"france\", \"celebration\", \"autumn\", \"literature\", \"progressed\", \"imagine\", \"measuring\", \"allied\", \"dismantle\", \"\\u00e9tablissements\", \"accommodation\", \"cardiac\", \"sparkled\", \"centennial\", \"calvayrac\", \"topped\", \"shaping\", \"invocation\", \"garden\", \"copyrighted\", \"pinnacle\", \"holding\", \"experimental\", \"disobeyed\", \"exterior\", \"restriction\", \"bulletin\", \"origin\", \"publish\", \"carriage\", \"dominion\", \"sandbox\", \"machine\", \"painting\", \"system\", \"intelligence\", \"language\", \"research\", \"artificial\", \"problem\", \"eiffel\", \"natural\", \"learning\", \"computer\", \"example\", \"people\", \"leonardo\", \"symbolic\", \"knowledge\", \"approach\", \"french\", \"intelligent\", \"algorithm\", \"processing\", \"sentence\", \"method\", \"structure\", \"however\", \"speech\", \"information\", \"researcher\", \"theory\", \"behavior\", \"ability\", \"commonsense\", \"artificial\", \"intelligent\", \"robotics\", \"ethical\", \"researcher\", \"intelligence\", \"simulate\", \"autonomous\", \"planning\", \"learner\", \"control\", \"narrow\", \"philosophical\", \"perception\", \"strategy\", \"humanity\", \"consciousness\", \"argues\", \"dangerous\", \"playing\", \"philosophy\", \"cybernetics\", \"reasoning\", \"physical\", \"singularity\", \"search\", \"automation\", \"function\", \"problem\", \"knowledge\", \"approach\", \"machine\", \"software\", \"social\", \"symbolic\", \"research\", \"computer\", \"technology\", \"system\", \"theory\", \"general\", \"development\", \"action\", \"environment\", \"whether\", \"example\", \"learning\", \"program\", \"algorithm\", \"people\", \"network\", \"include\", \"neural\", \"language\", \"described\", \"natural\", \"processing\", \"understanding\", \"eiffel\", \"exposition\", \"tallest\", \"restaurant\", \"hydraulic\", \"height\", \"monument\", \"completed\", \"gustave\", \"copyright\", \"minute\", \"transmitter\", \"together\", \"office\", \"passenger\", \"changed\", \"mounted\", \"edison\", \"communication\", \"engineer\", \"soci\\u00e9t\\u00e9\", \"bottom\", \"diameter\", \"taller\", \"chrysler\", \"lattice\", \"sauvestre\", \"located\", \"exploitation\", \"transmission\", \"design\", \"visitor\", \"construction\", \"second\", \"installed\", \"company\", \"structure\", \"aerial\", \"protest\", \"television\", \"france\", \"french\", \"building\", \"public\", \"replaced\", \"million\", \"pillar\", \"original\", \"system\", \"engineering\", \"artist\", \"mechanism\", \"leonardo\", \"painting\", \"portrait\", \"parsing\", \"italian\", \"grammar\", \"giocondo\", \"meaning\", \"louvre\", \"vasari\", \"morphology\", \"sentence\", \"renaissance\", \"corpus\", \"entity\", \"dictionary\", \"historian\", \"segmentation\", \"labelling\", \"sitter\", \"warping\", \"peruggia\", \"crosspiece\", \"humidity\", \"coreference\", \"gallery\", \"answer\", \"token_\", \"semantics\", \"trimmed\", \"speech\", \"semantic\", \"language\", \"museum\", \"analysis\", \"discourse\", \"linguistics\", \"english\", \"natural\", \"century\", \"translation\", \"statistical\", \"subject\", \"document\", \"however\", \"processing\", \"result\", \"cognitive\", \"learning\", \"method\", \"french\", \"system\", \"machine\", \"research\", \"example\", \"neural\", \"algorithm\"], \"Freq\": [57.0, 78.0, 87.0, 61.0, 36.0, 69.0, 84.0, 54.0, 23.0, 20.0, 27.0, 25.0, 40.0, 12.0, 21.0, 23.0, 20.0, 11.0, 20.0, 32.0, 19.0, 11.0, 48.0, 13.0, 41.0, 9.0, 11.0, 11.0, 14.0, 13.0, 0.0002937509856896653, 0.0002937455622371084, 0.0002937355609240599, 0.00029373413216505297, 0.0002937305748467092, 0.0002937310996969567, 0.00029372453906886364, 0.0002937211275422553, 0.0002937213608090319, 0.0002937217107091969, 0.00029371984457498375, 0.0002937187365577947, 0.0002937180367574648, 0.00029371771601564687, 0.000293718124232506, 0.000293717016215317, 0.0002937161414649046, 0.0002937168704235816, 0.0002937160539898633, 0.000293714829339286, 0.0002937143919640798, 0.0002937147418642447, 0.0002937145960725093, 0.00029371456691416225, 0.00029371377963879105, 0.00029371354637201444, 0.00029371252582986664, 0.0002937125549882137, 0.00029371173855449544, 0.00029371115538755384, 0.0002937112428625951, 0.00031127774737770263, 0.00030873032838504865, 0.0003083510366062306, 0.0003061436914155719, 0.0003051970948359632, 0.0003041152326842498, 0.00030326803690983715, 0.00030247767075388364, 0.00030193742489918334, 0.00030121910901886477, 0.00030113877777265905, 0.0003010459084372089, 0.0003005721144555042, 0.00030012088903443946, 0.0002997773453891416, 0.0002994549415454768, 0.00029938560299612026, 0.0002993174016222999, 0.00029913775704593933, 0.00029881226241748404, 0.00029879672101849035, 0.0002985543859959075, 0.00029836313639740905, 0.0002983394306612329, 0.0002982824260926913, 0.0002982481650348722, 0.00029797390162223666, 0.00029760061646291703, 0.00029740216475268984, 0.00029737020720429, 10.193240058923646, 9.361237344662356, 8.529113605097837, 58.45696107555748, 24.339156681865067, 7.6968540810467685, 7.696674019010257, 22.67489936328048, 83.41957321136287, 6.864997482700354, 6.864725913727254, 6.864702299033941, 6.032901785584145, 6.032856032115851, 6.032599222326072, 6.032782728172025, 6.03261053769995, 6.032811262593111, 6.0326808898071125, 6.032588890897747, 5.200631438131975, 5.20057830507202, 5.200586176636458, 5.200747051734653, 5.200398243035508, 13.521659253374008, 4.368641515162897, 4.368633151625682, 4.3685775587018405, 4.368550500199086, 11.857606595464803, 46.80601846862193, 34.3238701433244, 27.667777585154145, 62.61921213905534, 8.52900537108682, 8.529344832303195, 20.178788890158923, 34.32427946467516, 26.835971660003796, 14.354386151563563, 46.80698667104776, 16.850990565353587, 16.01857951368709, 12.69055488140417, 9.361570902205404, 7.697012988253855, 9.361405599352212, 21.843079662892368, 26.83769750050676, 10.193636588982194, 16.85121687283117, 15.186684049491266, 11.857916538314537, 10.19366709129439, 11.026284771527374, 14.359357044505963, 10.193457510891237, 11.860097945609331, 10.19457133725917, 10.193841249657574, 57.54535746857263, 12.21699886800034, 10.80066462660283, 8.67571771807543, 7.967573260452719, 7.2595565840034375, 6.551272290379611, 6.550883642735139, 5.134602924772537, 5.1347090072561405, 5.134792908856808, 4.426348044928256, 3.7183041245684127, 3.7182537353887013, 3.718245538105877, 3.7182778450440654, 3.7182947218028204, 3.718189603705432, 3.71808424451149, 10.09214454054954, 3.0102160835392526, 3.010135316193782, 3.0100685324484227, 3.0100584063931697, 3.0100957763589844, 3.010047557048256, 3.010057683103509, 3.009949671847477, 3.0100490036275778, 3.0099986144478663, 9.384432610144064, 7.968116209891523, 7.967546257638711, 16.466987194904164, 7.259613482790097, 7.9680197712700656, 12.217758804337423, 4.426633021054662, 4.4265949277991865, 4.426580462005968, 8.676116973968265, 13.634654318511814, 7.968316320031047, 7.9681036728707335, 5.13490092011284, 8.676820975904903, 4.4265529769988525, 7.968501482184245, 4.433526453716428, 4.427070852396078, 4.4267878050421015, 4.4267675529315955, 36.60442968392169, 77.86014181807076, 19.61630692309457, 13.144856498923177, 11.527078481546365, 10.71804470419569, 10.71822398166699, 7.482834599210629, 20.425907149920295, 6.673730120885355, 6.673484350830803, 18.806871665209574, 5.864889508697417, 5.864705601995637, 5.864700972765158, 5.055793447154834, 5.055777455267722, 5.055702125062646, 5.055735792193406, 5.055810280720213, 4.246961251749585, 4.24686824630086, 4.246996602236885, 4.246831633296157, 4.246805120430683, 4.246882554831433, 4.246852254413748, 4.246901071753351, 13.14449541894577, 3.438044257258735, 17.189657572273003, 13.95434646589566, 55.21054593176249, 12.336127409105885, 12.33620905189798, 7.482684780478745, 7.482540853494743, 9.10110836508789, 28.515332544183448, 13.95500381662376, 9.908965476218485, 14.76319002395754, 9.910043666081092, 9.100742235040869, 14.763838116224681, 14.763080605782568, 11.528090178825721, 12.336490172439829, 19.61628335610304, 11.527545612985667, 13.956136715573853, 22.856702607895027, 21.23891112366591, 13.955973429989665, 12.338024551924242, 10.71921463698962, 10.718920891273733], \"Total\": [57.0, 78.0, 87.0, 61.0, 36.0, 69.0, 84.0, 54.0, 23.0, 20.0, 27.0, 25.0, 40.0, 12.0, 21.0, 23.0, 20.0, 11.0, 20.0, 32.0, 19.0, 11.0, 48.0, 13.0, 41.0, 9.0, 11.0, 11.0, 14.0, 13.0, 1.2961586115807022, 1.2961628931680922, 1.2961708112618642, 1.2961700234838849, 1.2961720172503268, 1.2961743708304239, 1.2961802221481562, 1.2961762259425276, 1.296177645275196, 1.296180298463771, 1.29617827381131, 1.2961799939743057, 1.296179362162812, 1.2961799504375269, 1.2961830312854106, 1.2961809681536645, 1.2961808279957756, 1.2961847252237622, 1.2961818951580335, 1.2961840432046579, 1.2961824679402343, 1.2961851232428558, 1.2961845827887595, 1.296186129281133, 1.2961826835558876, 1.2961821251540544, 1.2961816408518598, 1.296186820242336, 1.296183815843883, 1.2961850359515774, 1.2961882179005648, 84.04153218387773, 78.96539552408011, 74.09752408369582, 87.86113566353278, 69.75311997653513, 48.46309909150435, 61.2739889533523, 54.37577883550992, 57.97054692805776, 41.26480291629046, 46.63786823603116, 37.636797790799314, 35.07031940210814, 26.49159066572963, 36.99582961533163, 26.22465473671599, 40.3746403446576, 32.9067756378527, 27.80126676913153, 25.531865462116617, 27.75053870010428, 25.137612967003456, 20.02756973939609, 18.447878488899292, 20.743913693871104, 23.101628703857337, 19.24191927164075, 18.64177527311869, 23.86811486409558, 22.087452229145654, 10.57495668200062, 9.74251017797605, 8.910243459527859, 61.2739889533523, 25.531865462116617, 8.078121333214819, 8.077970071105225, 23.86811486409558, 87.86113566353278, 7.245874202725322, 7.245693673664743, 7.24569133009481, 6.413652877099755, 6.413620640931838, 6.413432705016165, 6.413642634610407, 6.413471127309712, 6.413708106413712, 6.413615545736527, 6.4136793251467275, 5.58117922621005, 5.581180231251851, 5.581251879760774, 5.581458644054043, 5.581313337980392, 14.61237950934788, 4.749071834710761, 4.749084481620518, 4.74903364046028, 4.749022311656014, 13.04855709600518, 54.37577883550992, 40.3746403446576, 32.9067756378527, 84.04153218387773, 9.719223905064302, 9.719690551009192, 26.22465473671599, 48.46309909150435, 37.636797790799314, 17.972594461279712, 74.09752408369582, 22.087452229145654, 21.05385167566361, 16.308254890213703, 11.260485469973093, 8.78652316564164, 11.360597780086417, 35.07031940210814, 46.63786823603116, 13.001801561600042, 27.75053870010428, 26.49159066572963, 18.711850260954684, 15.227866104643674, 21.925516564831277, 69.75311997653513, 17.453539882247586, 41.26480291629046, 25.137612967003456, 17.856446424582664, 57.97054692805776, 12.630481662116129, 11.214032077255737, 9.088641085644497, 8.380284293747765, 7.672066676649456, 6.963464487365634, 6.9633308911623395, 5.5465298217101315, 5.546651571920366, 5.546815253747278, 4.838344974924333, 4.129759816732845, 4.1297475412393485, 4.129778078971314, 4.129897351994442, 4.129919350596113, 4.129857040720678, 4.129783142977416, 11.314725323896205, 3.4214725847702696, 3.4214340505486183, 3.4213926255089437, 3.4213902559995617, 3.421468554190538, 3.421419049605589, 3.4214592435394984, 3.421354160316016, 3.421472230793651, 3.42142391703562, 11.438177012423642, 9.998420276802044, 9.998533503942095, 23.400484619357446, 9.290041469558362, 10.877177249883292, 20.743913693871104, 5.647099828055276, 5.647213345832973, 5.647209006879183, 13.942833664291696, 27.80126676913153, 13.32729097899899, 14.899002103436665, 7.164729634623441, 18.03506868727357, 5.647322854502626, 17.326398143172344, 74.09752408369582, 10.640779249027558, 9.715692732150753, 8.167163657403526, 36.99582961533163, 78.96539552408011, 20.005473860537272, 13.532673448083449, 11.914426157143009, 11.105338792486268, 11.105679920922237, 7.869598878456353, 21.523110640949096, 7.060324408112405, 7.060328009870766, 20.02756973939609, 6.251232320580606, 6.251203174433174, 6.251291335263537, 5.4421296128212715, 5.442140200799384, 5.4421048008248825, 5.442188363580673, 5.442273185881603, 4.63309389350797, 4.63302308295624, 4.633169442591732, 4.633020772536692, 4.6330037253705285, 4.633088638593006, 4.633072441669036, 4.633187488590588, 14.364630275590669, 3.823999307809566, 19.24191927164075, 16.006575294747666, 69.75311997653513, 14.848687067831058, 15.220383512843265, 8.701455151450572, 8.701630478059819, 11.028169039476156, 41.26480291629046, 19.548605665567955, 12.792982491942665, 22.64128091215594, 13.378186392151925, 11.984126811472178, 23.101628703857337, 25.137612967003456, 17.369382831712024, 19.381559781814268, 46.63786823603116, 18.447878488899292, 27.80126676913153, 74.09752408369582, 84.04153218387773, 48.46309909150435, 35.07031940210814, 21.925516564831277, 27.75053870010428], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -8.134599685668945, -8.134699821472168, -8.134699821472168, -8.134699821472168, -8.134699821472168, -8.134699821472168, -8.134699821472168, -8.13479995727539, -8.13479995727539, -8.134699821472168, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.13479995727539, -8.076700210571289, -8.08489990234375, -8.086099624633789, -8.093299865722656, -8.096400260925293, -8.100000381469727, -8.102800369262695, -8.105400085449219, -8.107199668884277, -8.10949993133545, -8.109800338745117, -8.110099792480469, -8.111700057983398, -8.113200187683105, -8.114299774169922, -8.115400314331055, -8.115599632263184, -8.115900039672852, -8.116499900817871, -8.117600440979004, -8.117600440979004, -8.118399620056152, -8.119099617004395, -8.119199752807617, -8.11929988861084, -8.119500160217285, -8.120400428771973, -8.121600151062012, -8.122300148010254, -8.122400283813477, -6.027299880981445, -6.112400054931641, -6.20550012588501, -4.280700206756592, -5.156899929046631, -6.308199882507324, -6.308199882507324, -5.227799892425537, -3.925100088119507, -6.422599792480469, -6.422599792480469, -6.422599792480469, -6.551799774169922, -6.551799774169922, -6.551799774169922, -6.551799774169922, -6.551799774169922, -6.551799774169922, -6.551799774169922, -6.551799774169922, -6.700200080871582, -6.700200080871582, -6.700200080871582, -6.700200080871582, -6.700300216674805, -5.744699954986572, -6.874599933624268, -6.874599933624268, -6.874599933624268, -6.874599933624268, -5.875999927520752, -4.502999782562256, -4.813199996948242, -5.02869987487793, -4.211900234222412, -6.20550012588501, -6.20550012588501, -5.344399929046631, -4.813199996948242, -5.059299945831299, -5.684999942779541, -4.502999782562256, -5.524600028991699, -5.575300216674805, -5.808199882507324, -6.112400054931641, -6.308199882507324, -6.112400054931641, -5.265100002288818, -5.059199810028076, -6.027299880981445, -5.524600028991699, -5.628600120544434, -5.875999927520752, -6.027200222015381, -5.948699951171875, -5.684599876403809, -6.027299880981445, -5.875800132751465, -6.027200222015381, -6.027200222015381, -3.583199977874756, -5.132999897003174, -5.256199836730957, -5.475299835205078, -5.560400009155273, -5.653500080108643, -5.756100177764893, -5.756199836730957, -5.999800205230713, -5.999800205230713, -5.99970006942749, -6.148200035095215, -6.322500228881836, -6.322500228881836, -6.322500228881836, -6.322500228881836, -6.322500228881836, -6.3225998878479, -6.3225998878479, -5.323999881744385, -6.53380012512207, -6.53380012512207, -6.53380012512207, -6.53380012512207, -6.53380012512207, -6.53380012512207, -6.53380012512207, -6.533899784088135, -6.53380012512207, -6.53380012512207, -5.396699905395508, -5.560299873352051, -5.560400009155273, -4.834400177001953, -5.653500080108643, -5.560400009155273, -5.132900238037109, -6.148099899291992, -6.148200035095215, -6.148200035095215, -5.475200176239014, -5.023200035095215, -5.560299873352051, -5.560299873352051, -5.99970006942749, -5.475100040435791, -6.148200035095215, -5.560299873352051, -6.146599769592285, -6.148099899291992, -6.148099899291992, -6.148099899291992, -4.592700004577637, -3.837899923324585, -5.2164998054504395, -5.616799831390381, -5.7480998039245605, -5.820899963378906, -5.820899963378906, -6.180200099945068, -5.176000118255615, -6.2947001457214355, -6.2947001457214355, -5.258600234985352, -6.423900127410889, -6.423900127410889, -6.423900127410889, -6.572299957275391, -6.572299957275391, -6.572299957275391, -6.572299957275391, -6.572299957275391, -6.746600151062012, -6.746699810028076, -6.746600151062012, -6.746699810028076, -6.746699810028076, -6.746699810028076, -6.746699810028076, -6.746699810028076, -5.616799831390381, -6.957900047302246, -5.348499774932861, -5.55709981918335, -4.181700229644775, -5.680300235748291, -5.680300235748291, -6.180200099945068, -6.180300235748291, -5.984399795532227, -4.842400074005127, -5.557000160217285, -5.899400234222412, -5.500699996948242, -5.8993000984191895, -5.984499931335449, -5.500699996948242, -5.500699996948242, -5.7480998039245605, -5.680300235748291, -5.2164998054504395, -5.7480998039245605, -5.5569000244140625, -5.063600063323975, -5.13700008392334, -5.5569000244140625, -5.680200099945068, -5.820799827575684, -5.820799827575684], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8075, 0.8075, 0.8075, 0.8075, 0.8075, 0.8075, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, 0.8074, -3.3064, -3.2523, -3.1899, -3.3675, -3.1398, -2.7792, -3.0165, -2.8997, -2.9655, -2.628, -2.7506, -2.5365, -2.4674, -2.1884, -2.5235, -2.1805, -2.6122, -2.408, -2.24, -2.1559, -2.2393, -2.1412, -1.9146, -1.8325, -1.95, -2.0578, -1.8759, -1.8454, -2.0932, -2.0158, 0.8158, 0.8127, 0.8089, 0.8055, 0.8047, 0.8042, 0.8042, 0.8013, 0.8007, 0.7986, 0.7986, 0.7986, 0.7914, 0.7914, 0.7914, 0.7914, 0.7914, 0.7914, 0.7914, 0.7913, 0.782, 0.782, 0.7819, 0.7819, 0.7819, 0.775, 0.7691, 0.7691, 0.7691, 0.7691, 0.7569, 0.7027, 0.6902, 0.6792, 0.5583, 0.722, 0.7219, 0.5905, 0.5076, 0.5143, 0.6278, 0.3932, 0.582, 0.5793, 0.6018, 0.6679, 0.7202, 0.659, 0.3791, 0.3, 0.6093, 0.3538, 0.2962, 0.3964, 0.4512, 0.1652, -0.728, 0.3148, -0.3942, -0.0499, 0.292, 1.5585, 1.5325, 1.5283, 1.5193, 1.5153, 1.5105, 1.5048, 1.5048, 1.4886, 1.4886, 1.4886, 1.4768, 1.4609, 1.4609, 1.4608, 1.4608, 1.4608, 1.4608, 1.4608, 1.4515, 1.4378, 1.4377, 1.4377, 1.4377, 1.4377, 1.4377, 1.4377, 1.4377, 1.4377, 1.4377, 1.3679, 1.3388, 1.3388, 1.2144, 1.3192, 1.2546, 1.0365, 1.3223, 1.3223, 1.3223, 1.0914, 0.8533, 1.0515, 0.94, 1.2327, 0.8342, 1.3223, 0.7891, -1.2504, 0.6889, 0.7797, 0.9534, 0.9981, 0.9947, 0.9891, 0.9797, 0.9757, 0.9733, 0.9732, 0.9584, 0.9564, 0.9524, 0.9524, 0.9459, 0.945, 0.9449, 0.9449, 0.9351, 0.9351, 0.9351, 0.9351, 0.9351, 0.9217, 0.9217, 0.9217, 0.9217, 0.9217, 0.9217, 0.9217, 0.9217, 0.92, 0.9024, 0.896, 0.8716, 0.775, 0.8234, 0.7987, 0.8579, 0.8578, 0.8167, 0.6392, 0.6717, 0.7533, 0.5811, 0.7087, 0.7335, 0.561, 0.4765, 0.5988, 0.557, 0.1427, 0.5386, 0.3196, -0.1674, -0.3667, -0.2361, -0.0359, 0.2931, 0.0575]}, \"token.table\": {\"Topic\": [2, 3, 2, 3, 4, 3, 4, 2, 4, 3, 2, 4, 4, 2, 4, 2, 2, 4, 2, 3, 4, 2, 2, 3, 2, 3, 2, 3, 4, 3, 3, 3, 3, 3, 3, 2, 3, 4, 3, 3, 2, 4, 2, 3, 2, 3, 3, 2, 3, 4, 2, 3, 4, 2, 3, 3, 4, 4, 4, 2, 2, 2, 3, 4, 2, 3, 4, 2, 4, 3, 4, 2, 4, 3, 3, 2, 4, 3, 3, 3, 3, 4, 2, 3, 4, 2, 3, 4, 4, 2, 3, 2, 2, 3, 4, 3, 3, 3, 3, 3, 4, 3, 4, 2, 4, 4, 3, 2, 3, 4, 4, 4, 3, 3, 4, 3, 2, 3, 4, 2, 4, 3, 3, 2, 3, 4, 2, 4, 3, 4, 2, 4, 2, 4, 3, 4, 2, 4, 4, 2, 4, 3, 2, 2, 4, 4, 2, 4, 3, 3, 3, 4, 2, 4, 4, 3, 2, 3, 2, 3, 4, 2, 3, 4, 3, 3, 4, 3, 3, 4, 2, 2, 3, 4, 2, 4, 2, 4, 3, 3, 2, 3, 4, 3, 4, 4, 3, 2, 3, 4, 2, 4, 2, 2, 2, 3, 4, 3, 2, 2, 4, 2, 3, 4, 2, 4, 2, 4, 3, 3, 4, 2, 3, 4, 3, 2, 3, 4, 3, 4, 2, 4, 2, 4, 3, 3, 2, 3, 4, 2, 3, 3, 2, 2, 3, 4, 4, 2, 4, 2, 4, 2, 4, 3, 2, 2, 4, 2, 4, 3, 2, 4, 3, 2, 4, 2, 4, 2, 2, 3, 4, 2, 3, 4, 2, 4, 2, 3, 4, 3, 3, 2, 4, 3, 4, 2, 4, 3, 4, 3, 2, 4, 3, 3, 4, 2, 4, 4, 3, 4, 4, 2, 4, 3], \"Freq\": [0.9237865637898361, 0.7714976081531227, 0.7992550608940581, 0.08880611787711756, 0.08880611787711756, 0.7083281900078439, 0.17708204750196097, 0.6126007204298387, 0.3963887014546015, 0.7714976535768325, 0.19710410039724294, 0.7884164015889717, 0.863357966092804, 0.8508885923114136, 0.15194439148418099, 0.8958680231086746, 0.9465680460946524, 0.048960416177309604, 0.10292626862218923, 0.41170507448875693, 0.41170507448875693, 0.842278628631074, 0.9660910763371431, 0.7715079680732039, 0.9456303510936135, 0.8768253181787787, 0.30013601461115835, 0.6002720292223167, 0.15006800730557918, 0.771496520892963, 0.7714978153013777, 0.7714988132454796, 0.7714955145840546, 0.7715105165875276, 0.7714981654478702, 0.10230908711421353, 0.20461817422842707, 0.7161636097994947, 0.9685470749214358, 0.8768164758742755, 0.3611680421391113, 0.6191452150956194, 1.0100734105504336, 0.9685738600589454, 0.27580685053488385, 0.7354849347596902, 1.0052660299231506, 0.7173830289727894, 0.026569741813807016, 0.26569741813807013, 0.9355004663976924, 0.8001173368920413, 0.20002933422301034, 0.9355090261665768, 0.9014447608918215, 0.7714966577882016, 0.8633707713412418, 0.9598152279771403, 0.863339890665094, 0.8958464965540277, 0.8958678617835114, 0.5729496748204781, 0.17188490244614343, 0.22917986992819123, 0.08742651900856616, 0.7868386710770954, 0.08742651900856616, 0.7971423115174066, 0.18395591804247843, 0.8768359344767512, 0.9187579781672885, 0.11492330680268983, 0.8044631476188288, 0.7715000321602411, 0.7714950580946471, 0.25033112943432445, 0.7509933883029734, 0.7714947883701365, 0.968556528848268, 1.0005080695888344, 0.883804044175994, 0.08838040441759941, 0.4698903983424843, 0.37591231867398744, 0.09397807966849686, 0.09067688357155437, 0.09067688357155437, 0.8160919521439893, 0.9598016918766843, 0.9104852794655776, 0.1138106599331972, 0.9903478138172208, 0.627311081708527, 0.02851414007766032, 0.34216968093192385, 0.7714947364140037, 0.8768155336757225, 0.9500825321644545, 0.7714941376163327, 0.645492890232884, 0.35860716124049113, 0.5035741758193754, 0.5035741758193754, 0.9196419122596938, 0.07663682602164115, 0.8633549478593043, 0.7714949733166842, 0.7599559570610344, 0.0949944946326293, 0.14249174194894396, 0.9904841557045828, 0.9905145809187254, 0.9014645482350219, 0.912400829532029, 0.9187561906739485, 0.7714963168643236, 0.2597219476130774, 0.08657398253769247, 0.6493048690326935, 0.9355097693669089, 0.8633675945747816, 0.9546215521552792, 0.7715025372337383, 0.6566908279388234, 0.13133816558776468, 0.19700724838164702, 0.4827866374388676, 0.4827866374388676, 0.7534950218400663, 0.21528429195430465, 0.9446725150224706, 0.045526386266143165, 0.9400018199065967, 0.039166742496108194, 0.7714972929712698, 1.0071823721703699, 0.8421127645908282, 0.1486081349277932, 0.9187480597805445, 0.20070786804532303, 0.7884951958923405, 0.876829162550501, 0.9355043241306803, 0.5789286908088249, 0.4288360672657962, 1.00011272580482, 0.1149209912465701, 0.8044469387259906, 0.7715032550582339, 0.8768457924633276, 0.0464616856123685, 0.9292337122473701, 0.7496293601853885, 0.24987645339512948, 0.889498957712197, 0.7715011363473627, 0.48976611315655516, 0.48976611315655516, 0.3252406504959582, 0.0542067750826597, 0.6504813009919164, 0.11089505865931625, 0.4990277639669231, 0.38813270530760685, 0.9014181600193256, 1.005246743585848, 0.9914553530960002, 0.968541915817954, 0.13469204319975875, 0.8081522591985525, 0.9355364398393383, 0.2908047331364487, 0.024233727761370727, 0.7027781050797511, 0.641304832640733, 0.37409448570709425, 0.501698555994074, 0.501698555994074, 0.9685822099429325, 0.7714968091530696, 0.11543080007013008, 0.46172320028052033, 0.4040078002454553, 0.012663774978434128, 0.987774448317862, 0.9606379737066006, 0.9685750477411512, 0.5662174155289392, 0.11324348310578784, 0.30198262161543427, 0.9355308351589707, 0.8633671640262323, 0.9355058181168003, 0.8958231743464634, 0.8422698453967726, 0.7083002164133027, 0.17707505410332566, 0.7714953792577336, 0.966091388812778, 0.8958563612101864, 0.9997263818605132, 0.8643554355732154, 0.018390541182408838, 0.12873378827686185, 0.39781024606936083, 0.5967153691040412, 0.7691241827235955, 0.23073725481707866, 0.7715037239575792, 0.7083139515087673, 0.17707848787719183, 0.13423717817575662, 0.5369487127030265, 0.3355929454393915, 0.7714937263542299, 0.958091732495989, 0.0684351237497135, 0.9598107528729196, 0.6978630394980405, 0.2791452157992162, 0.7015647087654007, 0.2888795859622238, 0.9636286791378957, 0.04189689909295199, 0.9902470474068444, 0.7714961885284922, 0.2302902779422323, 0.11514513897111615, 0.6908708338266969, 0.9903292696417412, 0.7714928944653573, 0.8768188619124105, 0.8422766193781513, 0.08546831540170548, 0.6837465232136438, 0.2136707885042637, 0.9187621670281192, 0.1249486516117081, 0.8746405612819567, 0.06961543602686845, 0.9050006683492899, 0.049931170532034504, 0.9486922401086556, 0.7714972095481719, 0.9660670064306605, 0.8422676024148321, 0.9187337403368593, 0.9259554049347315, 0.10288393388163683, 0.8768154429626772, 0.9259998625312518, 0.10288887361458353, 0.7714977893879013, 0.10393973552044015, 0.8834877519237413, 0.3533368995790719, 0.6625066867107597, 0.9354962683755433, 0.04820691094060303, 0.5784829312872364, 0.3374483765842212, 0.14949709485085844, 0.14949709485085844, 0.7474854742542922, 0.7626411177112229, 0.22879233531336687, 0.6342991966494294, 0.05398291035314293, 0.3104017345305718, 0.8768365417360282, 0.9809139053837882, 0.7789637734363674, 0.16692080859350727, 0.7083144957318518, 0.17707862393296295, 0.7696677653734788, 0.22637287216867025, 0.9685793308833391, 0.8633365280058626, 0.771495981557721, 0.23450356489500973, 0.7816785496500325, 0.8768279151445375, 0.8267289787583938, 0.7845189704593427, 0.5600218409768907, 0.39201528868382346, 0.9914558588776613, 0.8001263978231938, 0.20003159945579846, 0.8633539686309659, 0.7922118337624606, 0.17604707416943569, 0.7714991873569047], \"Term\": [\"ability\", \"accommodation\", \"action\", \"action\", \"action\", \"aerial\", \"aerial\", \"algorithm\", \"algorithm\", \"allied\", \"analysis\", \"analysis\", \"answer\", \"approach\", \"approach\", \"argues\", \"artificial\", \"artificial\", \"artist\", \"artist\", \"artist\", \"automation\", \"autonomous\", \"autumn\", \"behavior\", \"bottom\", \"building\", \"building\", \"building\", \"bulletin\", \"calvayrac\", \"cardiac\", \"carriage\", \"celebration\", \"centennial\", \"century\", \"century\", \"century\", \"changed\", \"chrysler\", \"cognitive\", \"cognitive\", \"commonsense\", \"communication\", \"company\", \"company\", \"completed\", \"computer\", \"computer\", \"computer\", \"consciousness\", \"construction\", \"construction\", \"control\", \"copyright\", \"copyrighted\", \"coreference\", \"corpus\", \"crosspiece\", \"cybernetics\", \"dangerous\", \"described\", \"described\", \"described\", \"design\", \"design\", \"design\", \"development\", \"development\", \"diameter\", \"dictionary\", \"discourse\", \"discourse\", \"dismantle\", \"disobeyed\", \"document\", \"document\", \"dominion\", \"edison\", \"eiffel\", \"engineer\", \"engineer\", \"engineering\", \"engineering\", \"engineering\", \"english\", \"english\", \"english\", \"entity\", \"environment\", \"environment\", \"ethical\", \"example\", \"example\", \"example\", \"experimental\", \"exploitation\", \"exposition\", \"exterior\", \"france\", \"france\", \"french\", \"french\", \"function\", \"function\", \"gallery\", \"garden\", \"general\", \"general\", \"general\", \"giocondo\", \"grammar\", \"gustave\", \"height\", \"historian\", \"holding\", \"however\", \"however\", \"however\", \"humanity\", \"humidity\", \"hydraulic\", \"imagine\", \"include\", \"include\", \"include\", \"information\", \"information\", \"installed\", \"installed\", \"intelligence\", \"intelligence\", \"intelligent\", \"intelligent\", \"invocation\", \"italian\", \"knowledge\", \"knowledge\", \"labelling\", \"language\", \"language\", \"lattice\", \"learner\", \"learning\", \"learning\", \"leonardo\", \"linguistics\", \"linguistics\", \"literature\", \"located\", \"louvre\", \"louvre\", \"machine\", \"machine\", \"meaning\", \"measuring\", \"mechanism\", \"mechanism\", \"method\", \"method\", \"method\", \"million\", \"million\", \"million\", \"minute\", \"monument\", \"morphology\", \"mounted\", \"museum\", \"museum\", \"narrow\", \"natural\", \"natural\", \"natural\", \"network\", \"network\", \"neural\", \"neural\", \"office\", \"origin\", \"original\", \"original\", \"original\", \"painting\", \"painting\", \"parsing\", \"passenger\", \"people\", \"people\", \"people\", \"perception\", \"peruggia\", \"philosophical\", \"philosophy\", \"physical\", \"pillar\", \"pillar\", \"pinnacle\", \"planning\", \"playing\", \"portrait\", \"problem\", \"problem\", \"problem\", \"processing\", \"processing\", \"program\", \"program\", \"progressed\", \"protest\", \"protest\", \"public\", \"public\", \"public\", \"publish\", \"reasoning\", \"reasoning\", \"renaissance\", \"replaced\", \"replaced\", \"research\", \"research\", \"researcher\", \"researcher\", \"restaurant\", \"restriction\", \"result\", \"result\", \"result\", \"robotics\", \"sandbox\", \"sauvestre\", \"search\", \"second\", \"second\", \"second\", \"segmentation\", \"semantic\", \"semantic\", \"semantics\", \"semantics\", \"sentence\", \"sentence\", \"shaping\", \"simulate\", \"singularity\", \"sitter\", \"social\", \"social\", \"soci\\u00e9t\\u00e9\", \"software\", \"software\", \"sparkled\", \"speech\", \"speech\", \"statistical\", \"statistical\", \"strategy\", \"structure\", \"structure\", \"structure\", \"subject\", \"subject\", \"subject\", \"symbolic\", \"symbolic\", \"system\", \"system\", \"system\", \"taller\", \"tallest\", \"technology\", \"technology\", \"television\", \"television\", \"theory\", \"theory\", \"together\", \"token_\", \"topped\", \"translation\", \"translation\", \"transmission\", \"transmitter\", \"trimmed\", \"understanding\", \"understanding\", \"vasari\", \"visitor\", \"visitor\", \"warping\", \"whether\", \"whether\", \"\\u00e9tablissements\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el3341401170526452007689437700\", ldavis_el3341401170526452007689437700_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el3341401170526452007689437700\", ldavis_el3341401170526452007689437700_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el3341401170526452007689437700\", ldavis_el3341401170526452007689437700_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pwEz8DHJ1ve"
      },
      "source": [
        "Cada círculo na imagem acima corresponde a um tópico. A partir da saída do modelo LDA usando 4 tópicos, sabemos que o primeiro tópico está relacionado à Inteligência Artificial, o segundo tópico está relacionado ao PLN, o terceiro tópico está relacionado à Mona Lisa, enquanto o quarto tópico está relacionado à Torre Eiffel.\n",
        "\n",
        ">\n",
        "A distância entre os círculos mostra como os tópicos são diferentes uns dos outros. Você pode ver que os círculos 1 e 2 estão sobrepostos. Isso ocorre porque o tópico 1 (IA) e o tópico 2 (PLN) têm muitas palavras em comum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhBxsShCMRf-"
      },
      "source": [
        "Se você passar o mouse sobre qualquer palavra à direita, verá apenas o círculo do tópico que contém a palavra. Por exemplo, se você passar o mouse sobre a palavra \"*machine*\", verá que os tópicos 3 e 4 desaparecem, pois não contêm essa palavra. O tamanho do tópico 1 aumentará uma vez que a maioria das ocorrências da palavra \"*machine*\" estão dentro desse  tópico. Uma porcentagem menor está no tópico 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPNGTTbkM_3q"
      },
      "source": [
        "Da mesma forma, se você clicar em qualquer um dos círculos, uma lista dos termos mais frequentes para aquele tópico aparecerá à direita junto com a frequência de ocorrência naquele mesmo tópico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aPSmR7NZe2n"
      },
      "source": [
        "**Mais informações:**\n",
        "\n",
        "> https://stackabuse.com/python-for-nlp-working-with-the-gensim-library-part-2/"
      ]
    }
  ]
}
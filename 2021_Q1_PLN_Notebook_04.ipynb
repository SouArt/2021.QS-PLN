{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-Q1 PLN Notebook 04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2021.QS-PLN/blob/main/2021_Q1_PLN_Notebook_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q2Bo6Sill63"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2021.Q1]**\n",
        "\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhi4TLwolnvK"
      },
      "source": [
        "##**Modelo de Linguagem com N-gramas**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYPYP6mVSTVk"
      },
      "source": [
        "### **Bibliotecas**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFeFaUQEtEqC"
      },
      "source": [
        "# expressoes regulares\n",
        "import re\n",
        "\n",
        "# cria um dicinario com a frequencia dos termos em um iterable\n",
        "from collections import Counter\n",
        "\n",
        "## subsequencias de um iterable\n",
        "from itertools import islice\n",
        "\n",
        "# numeros e sequencias aleatoreas\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1K0PgaCSx_U"
      },
      "source": [
        "### **Funções principais**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SA9JstDuVaL"
      },
      "source": [
        "regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ]+\"       # raw string\n",
        "#regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ0-9]+\"   # raw string\n",
        "\n",
        "# usa expressoes regulares para quebrar um texto em tokens\n",
        "def get_tokens(fileName):\n",
        "  # leitura do documento\n",
        "  with open(fileName,'r') as document:\n",
        "     content  = document.read()  # devolve um vetor contendo as linhas do arquivo\n",
        "     content  = content.lower()\n",
        "\n",
        "  Words    = re.findall(regex, content)\n",
        "\n",
        "  return(Words)\n",
        "\n",
        "# similar ao get_tokens, mas removindo elementos da lista de stopwords\n",
        "def get_tokens_without_stopwords(fileName,stopwordsName=\"/content/stopwords.txt\"):\n",
        "   # leitura do documento\n",
        "   with open(fileName,'r') as document:\n",
        "      content  = document.read()  # devolve um vetor contendo as linhas do arquivo\n",
        "      content  = content.lower()\n",
        "\n",
        "   # leitura das stopwords\n",
        "   with open(stopwordsName,'r') as stopwordsfile:\n",
        "      stopwords = set([])\n",
        "      for s in stopwordsfile.readlines():                                                                                                                                                     \n",
        "        stopwords.add(s.strip().lower())\n",
        "\n",
        "   # remove as stopwords\n",
        "   Words    = [w for w in re.findall(regex, content) if w not in stopwords]\n",
        "\n",
        "   return(Words)\n",
        "\n",
        "# retirado de um exemplo na internet\n",
        "def window(seq, n=2):\n",
        "    \"Retorna uma janela deslizante (de tamanho n) sobre a sequencia seq\"\n",
        "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
        "    it = iter(seq)\n",
        "    result = tuple(islice(it, n))\n",
        "    if len(result) == n:\n",
        "        yield result    \n",
        "    for elem in it:\n",
        "        result = result[1:] + (elem,)\n",
        "        yield result\n",
        "\n",
        "# isa o Counter para contar a frequencia de unigramas e bigramas\n",
        "def ngrams(Words):\n",
        "    \"Retarna a contagem de unigramas e bigramas a partir da lista de palavras\"\n",
        "  \n",
        "    # Conta Unigramas (utilizando o counter de collections)\n",
        "    Unigrams = Counter(Words)\n",
        "\n",
        "    # windows retora uma janela delizante de tamanho 2\n",
        "    Bigrams  = Counter(window(Words,2))\n",
        "\n",
        "    return(Unigrams,Bigrams)\n",
        "\n",
        "# funcao auxiliar para calcular as probabilidades\n",
        "BigramProbabilities = lambda w1, w2 : bigrams [ (w1,w2) ] / unigrams[ w1 ]\n",
        "\n",
        "# aplica o score em uma lista de sentencas\n",
        "def score(phrases):\n",
        "\n",
        "    # loop sobre todas as sentencas de teste\n",
        "    for phrase in phrases:\n",
        "        Words = re.findall(regex, phrase)\n",
        "        P = float(1.0)\n",
        "        for w_0, w_1 in window(Words,2):\n",
        "            P = P * BigramProbabilities(w_0, w_1)\n",
        "\n",
        "        print ( \"{1:.20f} : Sentença: {0}\".format( phrase, P ) ) "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI3YD1xOTl8a"
      },
      "source": [
        "### **Testando o Modelo**\n",
        "\n",
        "Cria uma sequência de sentenças e um modelo de bigramas baseado no livro de **Machado de Assis**, e aplica a função score na lista de sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVj8TEvcwXE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acfeeb9a-83f0-432c-ecee-f29c51bb9e80"
      },
      "source": [
        "sentencas = [\"ele é\",\n",
        "             \"ele é uma\", \n",
        "             \"ele é uma pessoa\", \n",
        "             \"ele é uma pessoa de\", \n",
        "             \"ele é uma pessoa de verdade\"]\n",
        "\n",
        "words = get_tokens(\"/content/A-Semana-Machado-de-Assis.txt\")\n",
        "\n",
        "unigrams, bigrams = ngrams(words)\n",
        "score(sentencas)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02647657841140529586 : Sentença: ele é\n",
            "0.00069189664838167149 : Sentença: ele é uma\n",
            "0.00000842133213707000 : Sentença: ele é uma pessoa\n",
            "0.00000050654629395910 : Sentença: ele é uma pessoa de\n",
            "0.00000000051863038186 : Sentença: ele é uma pessoa de verdade\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbNTzxnmT_na"
      },
      "source": [
        "Repetimos o processo, agora considerando todas as obras de Machado de Assis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8OnobVXCM3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129d73d8-b5e2-419d-e00b-637ed2653efd"
      },
      "source": [
        "sentencas = [\"ele é\",\n",
        "             \"ele é uma\", \n",
        "             \"ele é uma pessoa\", \n",
        "             \"ele é uma pessoa de\", \n",
        "             \"ele é uma pessoa de verdade\"]\n",
        "\n",
        "words = get_tokens(\"/content/Todas-as-obras-Machado-de-Assis.txt\")\n",
        "\n",
        "unigrams, bigrams = ngrams(words)\n",
        "score(sentencas)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02488038277511961729 : Sentença: ele é\n",
            "0.00093406050182903407 : Sentença: ele é uma\n",
            "0.00000825483405278844 : Sentença: ele é uma pessoa\n",
            "0.00000046590235609081 : Sentença: ele é uma pessoa de\n",
            "0.00000000050723310908 : Sentença: ele é uma pessoa de verdade\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f4on2F4FSfl",
        "outputId": "5f5585af-303a-45f7-8970-5046792dcf70"
      },
      "source": [
        "print(len(words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1535663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0_OnhUnE-Qs",
        "outputId": "c722a99b-167e-44ad-b783-7798dcf05383"
      },
      "source": [
        "print(len(unigrams))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjXwxoRlFGl4",
        "outputId": "d9c012e5-cf48-4b41-e270-a5d101ce32d5"
      },
      "source": [
        "print(len(bigrams))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "618262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orahrwRdUHpn"
      },
      "source": [
        "### **Probabilidade da próxima palavra**\n",
        "\n",
        "Usamos o modelo de bigrama para calcular quais as palavras mais prováveis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGwISM_1EiHy"
      },
      "source": [
        "def next_prob(phrase,n=5):\n",
        "    # quebre a sentenca em palavras\n",
        "    Words = re.findall(regex, phrase)\n",
        "\n",
        "    # calcula as probabilidades de todas as palavras em que o bigrama eh w1 e armazena em prob\n",
        "    probs = {w2 : BigramProbabilities(w1,w2) for (w1,w2) in bigrams.keys() if w1 == Words[-1] }\n",
        "\n",
        "    # ordena e imprime as n mais relevantes\n",
        "    for w, p in islice(sorted(probs.items(), key = lambda item: item[1], reverse=True),n):\n",
        "        print ( \"{0} -> {1} ({2:.2f}%)\".format( phrase, w.upper(), p*100 ) )   "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55a4_4VWUbvC"
      },
      "source": [
        "**Teste da função `next_prob`**\n",
        "\n",
        "O usuário digita frases e modelo lista as 5 palavras mais prováveis de acordo com o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltyUH_zcLLL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e3c2ee-ff5d-4ce3-c919-e1a6cb6e4f08"
      },
      "source": [
        "words = get_tokens(\"/content/A-Semana-Machado-de-Assis.txt\")\n",
        "#words = get_tokens(\"/content/Todas-as-obras-Machado-de-Assis.txt\")\n",
        "\n",
        "unigrams, bigrams = ngrams(words)\n",
        "\n",
        "phrase = input(\"\\nDigite uma frase: \")\n",
        "\n",
        "while (phrase != \"\"):\n",
        "    next_prob(phrase)\n",
        "    phrase = input(\"\\nDigite uma frase:\")\n",
        "\n",
        "# frase: ele é uma pessoa\n",
        "# frase: estudar\n",
        "# frase: a semana que"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Digite uma frase: ele é uma pessoa\n",
            "ele é uma pessoa -> QUE (28.57%)\n",
            "ele é uma pessoa -> DE (6.02%)\n",
            "ele é uma pessoa -> A (4.51%)\n",
            "ele é uma pessoa -> É (2.26%)\n",
            "ele é uma pessoa -> NO (2.26%)\n",
            "\n",
            "Digite uma frase:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvF9UFUYU481"
      },
      "source": [
        "**Teste da função `next_prob`**\n",
        "\n",
        "O usuário digita frases e modelo lista as 5 palavras mais prováveis de acordo com o modelo, **sem considerar as *stopwords***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEzurfRyikTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5df05f7-fe92-473f-84bb-c04315298ff0"
      },
      "source": [
        "words = get_tokens_without_stopwords(\"/content/A-Semana-Machado-de-Assis.txt\")\n",
        "\n",
        "unigrams, bigrams = ngrams(words)\n",
        "\n",
        "phrase = input(\"\\nDigite uma frase: \")\n",
        "\n",
        "while (phrase != \"\"):\n",
        "    next_prob(phrase)\n",
        "    phrase = input(\"\\nDigite uma frase:\")\n",
        "\n",
        "# frase: que\n",
        "# frase: rio"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Digite uma frase: que\n",
            "\n",
            "Digite uma frase:a\n",
            "\n",
            "Digite uma frase:Rio\n",
            "\n",
            "Digite uma frase:rio\n",
            "rio -> JANEIRO (54.70%)\n",
            "rio -> GRANDE (15.38%)\n",
            "rio -> BRANCO (5.98%)\n",
            "rio -> CLARO (2.56%)\n",
            "rio -> NEWS (1.71%)\n",
            "\n",
            "Digite uma frase:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYpFk2qsVt_b"
      },
      "source": [
        "### **Classe NGrams**\n",
        "\n",
        "- Reorganiza e empacota as funções anteriores em uma classe\n",
        "\n",
        "- O parâmetro 'max_n' corresponde ao valor máximo de elementos no modelo *ngram*\n",
        "\n",
        "- Uma única tabela `Counter` é usada, pois a própria chave já contém a informação do número de *grams*\n",
        "\n",
        "- O método `probability` trata n-gramas que não aparecem na base\n",
        "\n",
        "- O método `generate` pega a primeira palavra acima de um `threshold` em uma lista de unigramas embaralhada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ-T2YrZothG"
      },
      "source": [
        "class NGrams(object):\n",
        "\n",
        "    def __init__(self,max_n,Words=None):\n",
        "        self.max_n   = max_n\n",
        "        self.Counts  = Counter()\n",
        "\n",
        "        if Words is not None:\n",
        "            self.update(Words)\n",
        "\n",
        "    def update(self, Words):\n",
        "\n",
        "        # conta os unigram, bigram, trigram, ..., ngram\n",
        "        # e armazena na mesma estrutura\n",
        "        for i in range(1,self.max_n+1):\n",
        "            self.Counts.update(window(Words,i))\n",
        "\n",
        "        # Caso especial: tupla vazia (util para o metodo 'probability')\n",
        "        # O valor eh igual ao numero de palavras\n",
        "        self.Counts[()] += len(Words)\n",
        "\n",
        "    # Calcula a probabilidade para a frase: Words\n",
        "    def probability(self, Words):\n",
        "        if len(Words) <= self.max_n:\n",
        "            return self._probability(Words)\n",
        "        else:\n",
        "            P = 1\n",
        "            for i in range(len(Words) - self.max_n + 1):\n",
        "                ngram = Words[i:i + self.max_n]\n",
        "                P     = P * self._probability(ngram)\n",
        "            return P\n",
        "\n",
        "    # Calcula a aproximacao para o n-grama usando seu prefixo\n",
        "    def _probability(self, ngram):\n",
        "        ngram        = tuple(ngram)\n",
        "        ngram_count  = self.Counts[ngram]\n",
        "        prefix_count = self.Counts[ngram[:-1]]\n",
        "\n",
        "        # Se uma tupla (n-grama) nao for observada devolvemos zero\n",
        "        if ngram_count and prefix_count:\n",
        "            return ngram_count / prefix_count\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "        # Geracao de frases de 'n_words'\n",
        "    def generate(self, n_words, threshold = random.random()):\n",
        "\n",
        "        # cria uma lista de unigrams\n",
        "        unigrams = [ngram for ngram in self.Counts.keys() if len(ngram) == 1]\n",
        "\n",
        "        # Tentamos gerar frases \n",
        "        words = []\n",
        "        \n",
        "        while len(words) < n_words:\n",
        "            # o prefixo para o proximo n-grama\n",
        "            if self.max_n == 1:\n",
        "                prefix = ()\n",
        "            else:\n",
        "                prefix = tuple(words[-self.max_n + 1:])\n",
        "           \n",
        "            total     = 0.0\n",
        "            random.shuffle(unigrams)\n",
        "            for unigram in unigrams:\n",
        "                total += self._probability(prefix + unigram)\n",
        "                if total >= threshold:\n",
        "                    words.extend(unigram)\n",
        "                    break\n",
        "            \n",
        "            # Se nao for possivel criar uma frase  \n",
        "            if total == 0.0:\n",
        "                raise RuntimeError('impossible sequence')\n",
        "\n",
        "        return(words)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GauQRUsXS48"
      },
      "source": [
        "### **Teste geração de sentenças**\n",
        "\n",
        "Usamos os n-gramas de todas as obras de Machado de Assis com 1, 2 e 5 gramas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fncG3lq10kuX"
      },
      "source": [
        "words = get_tokens(\"/content/Todas-as-obras-Machado-de-Assis.txt\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM9x7HJItyWQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "044a3edd-c631-4094-b55f-ca15bf10cfef"
      },
      "source": [
        "# unigrama\n",
        "ng = NGrams(1, Words=words)\n",
        "print(\" \".join(ng.generate(30)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "em das espécie historias amedrontar não jesuine da em a é foi não mãos a nomes prole voltaram da do dirão algumas dali do os dos mesma de em de\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egZDaUI0uAxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d413d47-18fc-42bb-83a5-ea48acd53d1b"
      },
      "source": [
        "# bigrama\n",
        "ng = NGrams(2, Words=words)\n",
        "print(\" \".join(ng.generate(30)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lhe disse que de desdém forcejando por que sou poeta a um deles não mas como me indigna margarida mas essa luta que além disso é na casaca -------------------------------------------------------------------------- texto-fonte\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0ogci0q11RX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66135da-b94d-4e3c-f465-7b0696854569"
      },
      "source": [
        "# 5-grama\n",
        "ng = NGrams(5, Words=words)\n",
        "print(\" \".join(ng.generate(30)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comia tão pouco que quase não olhava para o diplomata nem para o chão nem para as paredes ou móveis mas para o ar como aires insistisse ele acordou e\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkZnfLqPX9DY"
      },
      "source": [
        "Repetimos o teste, agora usando os n-gramas do **discurso do Bolsonaro na ONU**. Observem a dependência do corpus usado\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ-vHYVkLBFQ"
      },
      "source": [
        "words = get_tokens(\"/content/discurso_bolsonaro.txt\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa82J5ExLIXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9f672b-316b-49df-9ccd-9be12b4b904a"
      },
      "source": [
        "ng = NGrams(3, Words=words)\n",
        "print(\" \".join(ng.generate(30)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mais hospitaleiro acabamos de estender a isenção de vistos para países como estados unidos japão austrália e canadá e estamos estudando adotar medidas similares para china e índia dentre outros\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMW9vrpeYPwE"
      },
      "source": [
        "### **Geração de sentenças com pontuação**\n",
        "\n",
        "Considera os caracteres de pontuação e números como sendo gramas válidos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-yJZtesOLSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ae16b8-6961-4f52-d62a-61b3f9673c73"
      },
      "source": [
        "regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ]+|[,\\.-?]|[0-9]+\"   # raw string\n",
        "\n",
        "words = get_tokens(\"/content/Todas-as-obras-Machado-de-Assis.txt\")\n",
        "\n",
        "ng = NGrams(5, Words=words)\n",
        "print(\" \".join(ng.generate(30)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "das noites belas , o terrível cenário preparava a mais terríveis lances . então surge dos tronos a profética voz que anunciava ao teu crédulo esposo : tu serás rei\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0AOUZ2hP8Rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5fd6a63-468c-4c96-cfba-020dd3d33f4e"
      },
      "source": [
        "regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ]+|[,\\.-?]|[0-9]+\"   # raw string\n",
        "\n",
        "words = get_tokens(\"/content/discurso_bolsonaro.txt\")\n",
        "\n",
        "ng = NGrams(3,Words=words)\n",
        "print(\" \".join(ng.generate(50)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "disfarçados de boas intenções . estamos prontos para , em busca de prosperidade , estamos adotando políticas que nos é mais sagrado : a nossa soberania um deles por ocasião do encontro do g 7 ousou sugerir aplicar sanções ao brasil , sem sequer nos ouvir . agradeço a deus\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}